Hmm yes and no (for summarising my project as: inherent disagreements in NLI: which sentence encoder(s) capture them better?). 
Yes in the sense that I’d like to see if disagreements (and agreements too) can be captured by similarity measures between p/h pairs, and if so, to what extent. Specifically I plan to use S-BERT to obtain vector embeddings for p and h independently because S-BERT uses a Siamese network of 2 BERTs, one for p and one for h. 
No because I am not sure how to obtain independent sentence embeddings from BERT: 
If I were to use p/h pairs, separated by [SEP], as input, then from the first transformer layer each transformer would have already seen all input tokens because of their fully-connectedness. My understanding is that 
1) the layer corresponding to [CLS] would encode both sentence in it, and 
2) Softmax output was shown not to be able to correlate well with human disagreements (i.e. the model doesn’t learn potential human disagreements by default). 
If I were to use each p and h as a single input sentence, and use the vector corresponding to [CLS] as input sentence’s embedding, wouldn’t it be the same as an un-tuned BERT? Afterall, S-BERT fine-tuned two BERTs with shared weights to ensure one BERT sees only one sentence.
I can also include Universal Sentence Encoder, and compare the embeddings between it and S-BERT. 
 
Then my assumption (and hope) is that similarity measures between p and h vectors not only capture their inferential relationships, but disagreements as well. I plan to see if similarity can be interpreted this way. Finally, I plan to test if these embeddings can be used to predict the categorical distribution of human labels using soft labels. 
My idea was inspired by this paper, where the authors modelled annotators in parallel for hate speech data. But I’m not sure if we have annotator-level annotations (I checked MNLI which doesn’t), and it would not be quite scalable because the authors modelled each individual annotator. That’s why I thought about clustering disagreements, but then I need independent representation of p and h, and hence the use of S-BERT. And under the assumption (hope) that disagreements can be captured by similarity measures, I thought about using clustering ‘disagreement vectors’ and try to interpret the clusters. Hopefully it well reflect both the degree and type of disagreements.
 
I think a more accurate summary would be: “to what extent can inherent disagreements in NLI be captured in independent sentence embeddings?” I am, of course, open to suggestion to change because I am not sure how plausible my idea is, and there might be holes in my understanding too. S-BERT fine-tuned on SNLI which shows it works for inferencing, but for actual disagreements? That’s what I would like to find out with this project. 
 
